{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Baselines.ipynb","provenance":[],"authorship_tag":"ABX9TyND1WYA/GANrwpE0EcKJVV6"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"iHSSms0o6zdZ"},"source":["# install all the required packages first after a start of every new collab session\r\n","!pip install -r requirements.txt"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"R54nPMUeQhDE","executionInfo":{"status":"ok","timestamp":1615398628955,"user_tz":-60,"elapsed":931,"user":{"displayName":"Zohaib Akhtar Khan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhDxR5SUI_CQuZ4d1iYZsq0ZqAkxd2KNHJ9ahkuVg=s64","userId":"11760862558786327949"}}},"source":["# Let's import the library. We typically only need at most four methods:\r\n","from datasets import list_datasets, list_metrics, load_dataset, load_metric\r\n","\r\n","from pprint import pprint"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"id":"acEyu99LQh39"},"source":["# Currently available datasets and metrics\r\n","datasets = list_datasets()\r\n","metrics = list_metrics()\r\n","\r\n","print(f\"ðŸ¤© Currently {len(datasets)} datasets are available on the hub:\")\r\n","pprint(datasets, compact=True)\r\n","print(f\"ðŸ¤© Currently {len(metrics)} metrics are available on the hub:\")\r\n","pprint(metrics, compact=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xrx2Fx2nQ-qn","executionInfo":{"status":"ok","timestamp":1615398870409,"user_tz":-60,"elapsed":1208,"user":{"displayName":"Zohaib Akhtar Khan","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhDxR5SUI_CQuZ4d1iYZsq0ZqAkxd2KNHJ9ahkuVg=s64","userId":"11760862558786327949"}},"outputId":"6fce2a47-c209-4306-d561-7a0378ea260d"},"source":["# You can access various attributes of the datasets before downloading them\r\n","mlsum_dataset = list_datasets(with_details=True)[datasets.index('mlsum')]\r\n","\r\n","pprint(mlsum_dataset.__dict__)  # It's a simple python dataclass"],"execution_count":4,"outputs":[{"output_type":"stream","text":["{'author': None,\n"," 'citation': '@article{scialom2020mlsum,\\n'\n","             '  title={MLSUM: The Multilingual Summarization Corpus},\\n'\n","             '  author={Scialom, Thomas and Dray, Paul-Alexis and Lamprier, '\n","             'Sylvain and Piwowarski, Benjamin and Staiano, Jacopo},\\n'\n","             '  journal={arXiv preprint arXiv:2004.14900},\\n'\n","             '  year={2020}\\n'\n","             '}',\n"," 'description': 'We present MLSUM, the first large-scale MultiLingual '\n","                'SUMmarization dataset.\\n'\n","                'Obtained from online newspapers, it contains 1.5M+ '\n","                'article/summary pairs in five different languages -- namely, '\n","                'French, German, Spanish, Russian, Turkish.\\n'\n","                'Together with English newspapers from the popular CNN/Daily '\n","                'mail dataset, the collected data form a large scale '\n","                'multilingual dataset which can enable new research directions '\n","                'for the text summarization community.\\n'\n","                'We report cross-lingual comparative analyses based on '\n","                'state-of-the-art systems.\\n'\n","                'These highlight existing biases which motivate the use of a '\n","                'multi-lingual dataset.',\n"," 'etag': None,\n"," 'id': 'mlsum',\n"," 'key': '',\n"," 'lastModified': None,\n"," 'siblings': None,\n"," 'size': None}\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"JooALftpRsGn"},"source":[""],"execution_count":null,"outputs":[]}]}