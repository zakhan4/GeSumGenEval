{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "baselines.ipynb",
   "provenance": [],
   "collapsed_sections": [
    "795pU6wXvmbv",
    "kfZ3Qmp1wY95",
    "MZkS7m49wivU",
    "peNsjkZa_2cF",
    "sxkixNu5vZsy"
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "795pU6wXvmbv"
   },
   "source": [
    "# Installation of required packages"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aEy_J34U9-k2",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1620741480870,
     "user_tz": -120,
     "elapsed": 414,
     "user": {
      "displayName": "Zohaib Akhtar Khan",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhDxR5SUI_CQuZ4d1iYZsq0ZqAkxd2KNHJ9ahkuVg=s64",
      "userId": "11760862558786327949"
     }
    },
    "outputId": "2b59fcb2-ebb5-43a4-b402-732a6f857269"
   },
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ],
   "execution_count": 1,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "t0hB-v3G-ATo",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1620741482321,
     "user_tz": -120,
     "elapsed": 426,
     "user": {
      "displayName": "Zohaib Akhtar Khan",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhDxR5SUI_CQuZ4d1iYZsq0ZqAkxd2KNHJ9ahkuVg=s64",
      "userId": "11760862558786327949"
     }
    },
    "outputId": "3a47674a-9ba5-4510-8c00-c6c207abfb8d"
   },
   "source": [
    "cd /content/drive/My Drive/GeSumGenEval"
   ],
   "execution_count": 2,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "/content/drive/.shortcut-targets-by-id/1PcWXs_So5sTaP0wBAR77_ORSfd4aFtHq/GeSumGenEval\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "iHSSms0o6zdZ",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1620741486993,
     "user_tz": -120,
     "elapsed": 4260,
     "user": {
      "displayName": "Zohaib Akhtar Khan",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhDxR5SUI_CQuZ4d1iYZsq0ZqAkxd2KNHJ9ahkuVg=s64",
      "userId": "11760862558786327949"
     }
    },
    "outputId": "b14ca812-ebd1-4260-853a-aa8a54860358"
   },
   "source": [
    "# install all the required packages first after a start of every new collab session\n",
    "!pip install -r requirements.txt"
   ],
   "execution_count": 3,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk==3.5 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 1)) (3.5)\n",
      "Requirement already satisfied: rouge==0.3.1 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 2)) (0.3.1)\n",
      "Requirement already satisfied: summa==1.2.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 3)) (1.2.0)\n",
      "Requirement already satisfied: datasets==1.4.1 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 4)) (1.4.1)\n",
      "Requirement already satisfied: SoMaJo==2.1.3 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 5)) (2.1.3)\n",
      "Requirement already satisfied: summ-eval==0.24 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 6)) (0.24)\n",
      "Requirement already satisfied: boto3==1.17.54 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 7)) (1.17.54)\n",
      "Requirement already satisfied: botocore==1.20.54 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 8)) (1.20.54)\n",
      "Requirement already satisfied: certifi==2020.12.5 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 9)) (2020.12.5)\n",
      "Requirement already satisfied: chardet==4.0.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 10)) (4.0.0)\n",
      "Requirement already satisfied: click==7.1.2 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 11)) (7.1.2)\n",
      "Requirement already satisfied: dill==0.3.3 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 12)) (0.3.3)\n",
      "Requirement already satisfied: filelock==3.0.12 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 13)) (3.0.12)\n",
      "Requirement already satisfied: idna==2.10 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 14)) (2.10)\n",
      "Requirement already satisfied: jmespath==0.10.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 15)) (0.10.0)\n",
      "Requirement already satisfied: joblib==1.0.1 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 16)) (1.0.1)\n",
      "Requirement already satisfied: multiprocess==0.70.11.1 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 17)) (0.70.11.1)\n",
      "Requirement already satisfied: numpy==1.20.2 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 18)) (1.20.2)\n",
      "Requirement already satisfied: packaging==20.9 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 19)) (20.9)\n",
      "Requirement already satisfied: protobuf==3.15.8 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 20)) (3.15.8)\n",
      "Requirement already satisfied: pyparsing==2.4.7 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 21)) (2.4.7)\n",
      "Requirement already satisfied: pyrouge==0.1.3 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 22)) (0.1.3)\n",
      "Requirement already satisfied: python-dateutil==2.8.1 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 23)) (2.8.1)\n",
      "Requirement already satisfied: regex==2021.4.4 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 24)) (2021.4.4)\n",
      "Requirement already satisfied: requests==2.25.1 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 25)) (2.25.1)\n",
      "Requirement already satisfied: s3transfer==0.4.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 26)) (0.4.0)\n",
      "Requirement already satisfied: sacremoses==0.0.45 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 27)) (0.0.45)\n",
      "Requirement already satisfied: six==1.15.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 28)) (1.15.0)\n",
      "Requirement already satisfied: tensorboardX==2.2 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 29)) (2.2)\n",
      "Requirement already satisfied: tokenizers==0.10.2 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 30)) (0.10.2)\n",
      "Requirement already satisfied: torch==1.8.1 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 31)) (1.8.1+cu101)\n",
      "Requirement already satisfied: tqdm==4.60.0 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 32)) (4.60.0)\n",
      "Requirement already satisfied: transformers==4.5.1 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 33)) (4.5.1)\n",
      "Requirement already satisfied: typing-extensions==3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 34)) (3.7.4.3)\n",
      "Requirement already satisfied: urllib3==1.26.4 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 35)) (1.26.4)\n",
      "Requirement already satisfied: pandas==1.2.4 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 36)) (1.2.4)\n",
      "Requirement already satisfied: scipy>=0.19 in /usr/local/lib/python3.7/dist-packages (from summa==1.2.0->-r requirements.txt (line 3)) (1.4.1)\n",
      "Requirement already satisfied: pyarrow>=0.17.1 in /usr/local/lib/python3.7/dist-packages (from datasets==1.4.1->-r requirements.txt (line 4)) (3.0.0)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.7/dist-packages (from datasets==1.4.1->-r requirements.txt (line 4)) (2.0.2)\n",
      "Requirement already satisfied: huggingface-hub==0.0.2 in /usr/local/lib/python3.7/dist-packages (from datasets==1.4.1->-r requirements.txt (line 4)) (0.0.2)\n",
      "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from datasets==1.4.1->-r requirements.txt (line 4)) (3.10.1)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.7/dist-packages (from datasets==1.4.1->-r requirements.txt (line 4)) (2021.4.0)\n",
      "Requirement already satisfied: pyemd==0.5.1 in /usr/local/lib/python3.7/dist-packages (from summ-eval==0.24->-r requirements.txt (line 6)) (0.5.1)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.7/dist-packages (from summ-eval==0.24->-r requirements.txt (line 6)) (2.5.1)\n",
      "Requirement already satisfied: bert-score in /usr/local/lib/python3.7/dist-packages (from summ-eval==0.24->-r requirements.txt (line 6)) (0.3.9)\n",
      "Requirement already satisfied: sklearn in /usr/local/lib/python3.7/dist-packages (from summ-eval==0.24->-r requirements.txt (line 6)) (0.0)\n",
      "Requirement already satisfied: pytorch-pretrained-bert in /usr/local/lib/python3.7/dist-packages (from summ-eval==0.24->-r requirements.txt (line 6)) (0.6.2)\n",
      "Requirement already satisfied: gin-config in /usr/local/lib/python3.7/dist-packages (from summ-eval==0.24->-r requirements.txt (line 6)) (0.4.0)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.7/dist-packages (from summ-eval==0.24->-r requirements.txt (line 6)) (5.4.8)\n",
      "Requirement already satisfied: sacrebleu in /usr/local/lib/python3.7/dist-packages (from summ-eval==0.24->-r requirements.txt (line 6)) (1.5.1)\n",
      "Requirement already satisfied: wmd in /usr/local/lib/python3.7/dist-packages (from summ-eval==0.24->-r requirements.txt (line 6)) (1.3.2)\n",
      "Requirement already satisfied: spacy==2.2.0 in /usr/local/lib/python3.7/dist-packages (from summ-eval==0.24->-r requirements.txt (line 6)) (2.2.0)\n",
      "Requirement already satisfied: stanza in /usr/local/lib/python3.7/dist-packages (from summ-eval==0.24->-r requirements.txt (line 6)) (1.2)\n",
      "Requirement already satisfied: moverscore in /usr/local/lib/python3.7/dist-packages (from summ-eval==0.24->-r requirements.txt (line 6)) (1.0.3)\n",
      "Requirement already satisfied: blanc in /usr/local/lib/python3.7/dist-packages (from summ-eval==0.24->-r requirements.txt (line 6)) (0.2.0)\n",
      "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas==1.2.4->-r requirements.txt (line 36)) (2018.9)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->datasets==1.4.1->-r requirements.txt (line 4)) (3.4.1)\n",
      "Requirement already satisfied: decorator<5,>=4.3 in /usr/local/lib/python3.7/dist-packages (from networkx->summ-eval==0.24->-r requirements.txt (line 6)) (4.4.2)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from bert-score->summ-eval==0.24->-r requirements.txt (line 6)) (3.2.2)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from sklearn->summ-eval==0.24->-r requirements.txt (line 6)) (0.22.2.post1)\n",
      "Requirement already satisfied: portalocker==2.0.0 in /usr/local/lib/python3.7/dist-packages (from sacrebleu->summ-eval==0.24->-r requirements.txt (line 6)) (2.0.0)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy==2.2.0->summ-eval==0.24->-r requirements.txt (line 6)) (1.0.5)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy==2.2.0->summ-eval==0.24->-r requirements.txt (line 6)) (3.0.5)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy==2.2.0->summ-eval==0.24->-r requirements.txt (line 6)) (2.0.5)\n",
      "Requirement already satisfied: srsly<1.1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from spacy==2.2.0->summ-eval==0.24->-r requirements.txt (line 6)) (1.0.5)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.2.0 in /usr/local/lib/python3.7/dist-packages (from spacy==2.2.0->summ-eval==0.24->-r requirements.txt (line 6)) (0.8.2)\n",
      "Requirement already satisfied: plac<1.0.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy==2.2.0->summ-eval==0.24->-r requirements.txt (line 6)) (0.9.6)\n",
      "Requirement already satisfied: thinc<7.2.0,>=7.1.1 in /usr/local/lib/python3.7/dist-packages (from spacy==2.2.0->summ-eval==0.24->-r requirements.txt (line 6)) (7.1.1)\n",
      "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy==2.2.0->summ-eval==0.24->-r requirements.txt (line 6)) (0.4.1)\n",
      "Requirement already satisfied: typing in /usr/local/lib/python3.7/dist-packages (from moverscore->summ-eval==0.24->-r requirements.txt (line 6)) (3.7.4.3)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->bert-score->summ-eval==0.24->-r requirements.txt (line 6)) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->bert-score->summ-eval==0.24->-r requirements.txt (line 6)) (0.10.0)\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hQLbRkRYY5z9",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1620741490242,
     "user_tz": -120,
     "elapsed": 2632,
     "user": {
      "displayName": "Zohaib Akhtar Khan",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhDxR5SUI_CQuZ4d1iYZsq0ZqAkxd2KNHJ9ahkuVg=s64",
      "userId": "11760862558786327949"
     }
    },
    "outputId": "c2348b7f-e355-441b-c3ac-c33cd146f1b5"
   },
   "source": [
    "import sys\n",
    "import nltk\n",
    "\n",
    "print(sys.executable)\n",
    "\n",
    "nltk.download('punkt')\n",
    "#nltk.download('stopwords')"
   ],
   "execution_count": 4,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "/usr/bin/python3\n"
     ],
     "name": "stdout"
    },
    {
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ],
     "name": "stderr"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {
      "tags": []
     },
     "execution_count": 4
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kfZ3Qmp1wY95"
   },
   "source": [
    "# Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "6juln3GJr8YD",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1620741491822,
     "user_tz": -120,
     "elapsed": 324,
     "user": {
      "displayName": "Zohaib Akhtar Khan",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhDxR5SUI_CQuZ4d1iYZsq0ZqAkxd2KNHJ9ahkuVg=s64",
      "userId": "11760862558786327949"
     }
    }
   },
   "source": [
    "import re\n",
    "import string\n",
    "#from nltk.corpus import stopwords\n",
    "\n",
    "punctuations = string.punctuation.replace('.', '')\n",
    "#stop_words = stopwords.words(\"german\")\n",
    "def clean_text(x):\n",
    "    # Lowercase the text\n",
    "    x = x.strip().lower()\n",
    "    # Remove stop words\n",
    "    #x = ' '.join([word for word in x.split(' ') if word not in stop_words])\n",
    "    # Remove unicode characters\n",
    "    #x = x.encode('ascii', 'ignore').decode()\n",
    "    # Remove URL\n",
    "    x = re.sub(r'https*\\S+', ' ', x)\n",
    "    # Remove mentions\n",
    "    #x = re.sub(r'@\\S+', ' ', x)\n",
    "    # Remove Hashtags\n",
    "    #x = re.sub(r'#\\S+', ' ', x)\n",
    "    # Remove ticks and the next character\n",
    "    #x = re.sub(r'\\'\\w+', '', x)\n",
    "    # Remove punctuations\n",
    "    x = re.sub('[%s]' % re.escape(punctuations), '', x)\n",
    "    # Remove numbers\n",
    "    #x = re.sub(r'\\w*\\d+\\w*', '', x)\n",
    "    # Replace the over spaces\n",
    "    x = re.sub(r'\\s{2,}', ' ', x)\n",
    "    return x"
   ],
   "execution_count": 5,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MZkS7m49wivU"
   },
   "source": [
    "# Summary Generation"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "oPWiQvhwo7fi",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1620741495853,
     "user_tz": -120,
     "elapsed": 328,
     "user": {
      "displayName": "Zohaib Akhtar Khan",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhDxR5SUI_CQuZ4d1iYZsq0ZqAkxd2KNHJ9ahkuVg=s64",
      "userId": "11760862558786327949"
     }
    }
   },
   "source": [
    "import nltk\n",
    "import random\n",
    "\n",
    "def get_random_summary(source: str, num_sent=3, language='german') -> str:\n",
    "    sentences = nltk.sent_tokenize(source, language)\n",
    "\n",
    "    return \" \".join(random.sample(sentences, num_sent))   \n",
    "\n",
    "def get_lead_summary(source: str, num_sent=3, language='german') -> str:\n",
    "    sentences = nltk.sent_tokenize(source, language)\n",
    "\n",
    "    return \" \".join(sentences[:3])\n",
    "\n",
    "from summa.summarizer import summarize\n",
    "\n",
    "def get_textrank_summary(source: str, ratio: float, language='german') -> str:\n",
    "    # By default ratio value is 0.2.\n",
    "    return summarize(source, language=language, ratio=ratio)\n",
    "\n",
    "from itertools import combinations\n",
    "def get_oracle_summary(source: str, reference: str, num_sent=3, language='german') -> str:\n",
    "    sentences = nltk.sent_tokenize(source, language)\n",
    "    max_score = 0\n",
    "    oracle_summary = \"\"\n",
    "\n",
    "    candidates = combinations(sentences, num_sent)\n",
    "    for summary in candidates:\n",
    "        summary = \" \".join(summary)\n",
    "        score = get_rouge([summary], [reference], False)[0]['rouge-l']['f']\n",
    "        if score > max_score:\n",
    "            max_score = score\n",
    "            oracle_summary = summary\n",
    "\n",
    "    return oracle_summary"
   ],
   "execution_count": 6,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QmQ36u_AwqRP"
   },
   "source": [
    "# Summary Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "WGivYz9zrXCg",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1620741526332,
     "user_tz": -120,
     "elapsed": 16502,
     "user": {
      "displayName": "Zohaib Akhtar Khan",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhDxR5SUI_CQuZ4d1iYZsq0ZqAkxd2KNHJ9ahkuVg=s64",
      "userId": "11760862558786327949"
     }
    },
    "outputId": "33e0645d-a10c-4a60-97df-37308a548e21"
   },
   "source": [
    "from rouge import Rouge\n",
    "from importlib import reload\n",
    "import src.gerouge as gerouge\n",
    "from summ_eval.bleu_metric import BleuMetric\n",
    "from summ_eval.meteor_metric import MeteorMetric\n",
    "from summ_eval.bert_score_metric import BertScoreMetric\n",
    "\n",
    "gerouge = reload(gerouge)\n",
    "\n",
    "def get_rouge(hypothesis, references, avg = True, language='german'):\n",
    "    if language == 'german':\n",
    "        rouge = gerouge.GeRouge(minimal_mode=True)\n",
    "    else:\n",
    "        rouge = Rouge()\n",
    "\n",
    "    rouge_scores = rouge.get_scores(hypothesis, references, avg, True)\n",
    "    if avg:\n",
    "        return {k: v['f'] for k, v in rouge_scores.items()}\n",
    "    else:\n",
    "        return rouge_scores\n",
    "\n",
    "def get_bleu(hypothesis, references):\n",
    "    metric = BleuMetric(force=True)\n",
    "    return metric.evaluate_batch(hypothesis, references)['bleu']\n",
    "\n",
    "def get_meteor(hypothesis, references):\n",
    "    metric = MeteorMetric()\n",
    "    return metric.evaluate_batch(hypothesis, references)['meteor']\n",
    "\n",
    "def get_bert_score(hypothesis, references):\n",
    "    metric = BertScoreMetric(lang='de', model_type='dbmdz/bert-base-german-cased', num_layers=9, verbose=False, idf=True, rescale_with_baseline=False)\n",
    "    return metric.evaluate_batch(hypothesis, references)['bert_score_f1']"
   ],
   "execution_count": 7,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Downloading the meteor jar\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "peNsjkZa_2cF"
   },
   "source": [
    "# Data Preprocessing for BertSum"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "f515bTAxAD8q",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1620312975814,
     "user_tz": -120,
     "elapsed": 1473,
     "user": {
      "displayName": "Zohaib Akhtar Khan",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhDxR5SUI_CQuZ4d1iYZsq0ZqAkxd2KNHJ9ahkuVg=s64",
      "userId": "11760862558786327949"
     }
    }
   },
   "source": [
    "import nltk\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "def data_prep_for_BertSum(dataset: pd.DataFrame, language: str, save_path: str, corpus_type: str) -> None:\n",
    "    print(f\"Sentence splitting, tokenizing and converting '{corpus_type}' split to json...\")\n",
    "    dataset_json = []\n",
    "    p_ct = 0\n",
    "    shard_size = 2000\n",
    "    for index, row in dataset.iterrows():\n",
    "        src_tokens = []\n",
    "        tgt_tokens = []\n",
    "\n",
    "        src_sentences = nltk.sent_tokenize(row['text'], language)\n",
    "        for sent in src_sentences:\n",
    "            src_tokens.append(nltk.word_tokenize(sent, language))\n",
    "\n",
    "        tgt_sentences = nltk.sent_tokenize(row['summary'], language)\n",
    "        for sent in tgt_sentences:\n",
    "            tgt_tokens.append(nltk.word_tokenize(sent, language))\n",
    "\n",
    "        dataset_json.append({'src': src_tokens, 'tgt': tgt_tokens})\n",
    "        if (len(dataset_json) >= shard_size):\n",
    "                pt_file = \"{:s}/{:s}.{:d}.json\".format(save_path, corpus_type, p_ct)\n",
    "                with open(pt_file, 'w') as save:\n",
    "                    # save.write('\\n'.join(dataset_json))\n",
    "                    save.write(json.dumps(dataset_json))\n",
    "                    p_ct += 1\n",
    "                    dataset_json = []\n",
    "\n",
    "    if (len(dataset_json) > 0):\n",
    "        pt_file = \"{:s}/{:s}.{:d}.json\".format(save_path, corpus_type, p_ct)\n",
    "        with open(pt_file, 'w') as save:\n",
    "            # save.write('\\n'.join(dataset_json))\n",
    "            save.write(json.dumps(dataset_json))\n",
    "            p_ct += 1\n",
    "            dataset_json = []"
   ],
   "execution_count": 12,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZnGpbfoHl8HS"
   },
   "source": [
    "# MLSUM"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "R54nPMUeQhDE",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1620314905147,
     "user_tz": -120,
     "elapsed": 1930778,
     "user": {
      "displayName": "Zohaib Akhtar Khan",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhDxR5SUI_CQuZ4d1iYZsq0ZqAkxd2KNHJ9ahkuVg=s64",
      "userId": "11760862558786327949"
     }
    },
    "outputId": "cf3223d5-bc47-4ac3-f59f-014ad0576fe5"
   },
   "source": [
    "# Let's import the library. We typically only need at most four methods:\n",
    "from datasets import list_datasets, list_metrics, load_dataset, load_metric\n",
    "from pprint import pprint\n",
    "import pandas as pd\n",
    "\n",
    "def load_mlsum_to_csv(corpus_type: str) -> pd.DataFrame:\n",
    "    # Downloading and loading a dataset\n",
    "    hf_split: str = corpus_type\n",
    "    if hf_split == \"valid\":\n",
    "        hf_split = \"validation\"\n",
    "    mlsum_dataset = load_dataset('mlsum', 'de', split=hf_split)\n",
    "\n",
    "    # Saving dataframe in the form of csv\n",
    "    df = pd.DataFrame(mlsum_dataset, columns=[\"text\",\"summary\"])\n",
    "    df.to_csv(f\"data/mlsum/{corpus_type}.csv\", index=False)\n",
    "\n",
    "    return df\n",
    "\n",
    "for corpus_type in ['train', 'valid', 'test']:\n",
    "    mlsum_dataset = load_mlsum_to_csv(corpus_type)\n",
    "    data_prep_for_BertSum(mlsum_dataset, 'german', \"json_data/mlsum\", corpus_type)"
   ],
   "execution_count": 13,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Reusing dataset mlsum (/root/.cache/huggingface/datasets/mlsum/de/1.0.0/fa51ffa9847464afce0f114ce70ab956e57905627bb24435851ddb91312a2238)\n"
     ],
     "name": "stderr"
    },
    {
     "output_type": "stream",
     "text": [
      "Sentence splitting, tokenizing and converting 'train' split to json...\n"
     ],
     "name": "stdout"
    },
    {
     "output_type": "stream",
     "text": [
      "Reusing dataset mlsum (/root/.cache/huggingface/datasets/mlsum/de/1.0.0/fa51ffa9847464afce0f114ce70ab956e57905627bb24435851ddb91312a2238)\n"
     ],
     "name": "stderr"
    },
    {
     "output_type": "stream",
     "text": [
      "Sentence splitting, tokenizing and converting 'valid' split to json...\n"
     ],
     "name": "stdout"
    },
    {
     "output_type": "stream",
     "text": [
      "Reusing dataset mlsum (/root/.cache/huggingface/datasets/mlsum/de/1.0.0/fa51ffa9847464afce0f114ce70ab956e57905627bb24435851ddb91312a2238)\n"
     ],
     "name": "stderr"
    },
    {
     "output_type": "stream",
     "text": [
      "Sentence splitting, tokenizing and converting 'test' split to json...\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "wVCgvT8d7l8M",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1620312974319,
     "user_tz": -120,
     "elapsed": 226952,
     "user": {
      "displayName": "Zohaib Akhtar Khan",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhDxR5SUI_CQuZ4d1iYZsq0ZqAkxd2KNHJ9ahkuVg=s64",
      "userId": "11760862558786327949"
     }
    },
    "outputId": "a7874c82-5bc8-4a74-cddb-b42ecda0b420"
   },
   "source": [
    "import itertools\n",
    "#merged_mlsum_dataset = itertools.chain(mlsum_dataset['train'], mlsum_dataset['test'], mlsum_dataset['validation'])\n",
    "mlsum_dataset = pd.read_csv(\"data/mlsum/test.csv\").iterrows()\n",
    "mlsum_src, mlsum_rnd_sum, mlsum_lead_sum, mlsum_textrank_sum, mlsum_tgt = map(list,zip(*[(\n",
    "                                                      row['text'],\n",
    "                                                      get_random_summary(row['text']),\n",
    "                                                      get_lead_summary(row['text']),\n",
    "                                                      get_textrank_summary(row['text'], 0.05),\n",
    "                                                      row['summary']\n",
    "                                                    ) for index, row in mlsum_dataset]))\n",
    "print(len(mlsum_src))\n",
    "print(len(mlsum_rnd_sum))\n",
    "print(len(mlsum_lead_sum))\n",
    "print(len(mlsum_textrank_sum))\n",
    "print(len(mlsum_tgt))"
   ],
   "execution_count": 11,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "10701\n",
      "10701\n",
      "10701\n",
      "10701\n",
      "10701\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "4awNdHuqsgr7",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1620741558664,
     "user_tz": -120,
     "elapsed": 2837,
     "user": {
      "displayName": "Zohaib Akhtar Khan",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhDxR5SUI_CQuZ4d1iYZsq0ZqAkxd2KNHJ9ahkuVg=s64",
      "userId": "11760862558786327949"
     }
    }
   },
   "source": [
    "import pandas as pd\n",
    "\n",
    "mlsum_oracle_sum = pd.read_csv(\"results/mlsum/oracle_step0_hypo.csv\")['hypothesis'].fillna('').tolist()\n",
    "mlsum_oracle_tgt = pd.read_csv(\"results/mlsum/oracle_step0_ref.csv\")['references'].fillna('').tolist()\n",
    "mlsum_bertsum_sum = pd.read_csv(\"results/mlsum/bertsum_step50000_hypo.csv\")['hypothesis'].fillna('').tolist()\n",
    "mlsum_bertsum_tgt = pd.read_csv(\"results/mlsum/bertsum_step50000_ref.csv\")['references'].fillna('').tolist()"
   ],
   "execution_count": 8,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "mPYaAUXc7qCE"
   },
   "source": [
    "oracle_rouge = get_rouge(mlsum_oracle_sum, mlsum_oracle_tgt)\n",
    "oracle_bleu = get_bleu(mlsum_oracle_sum, mlsum_oracle_tgt)\n",
    "oracle_meteor = get_meteor(mlsum_oracle_sum, mlsum_oracle_tgt)\n",
    "oracle_bert_score = get_bert_score(mlsum_oracle_sum, mlsum_oracle_tgt)\n",
    "print(\"Done\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "_YInfLYb7rNZ",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1620316305585,
     "user_tz": -120,
     "elapsed": 3331187,
     "user": {
      "displayName": "Zohaib Akhtar Khan",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhDxR5SUI_CQuZ4d1iYZsq0ZqAkxd2KNHJ9ahkuVg=s64",
      "userId": "11760862558786327949"
     }
    },
    "outputId": "629d65bd-2e3d-4c19-9b34-8ea9f8d2b492"
   },
   "source": [
    "bertsum_rouge = get_rouge(mlsum_bertsum_sum, mlsum_bertsum_tgt)\n",
    "bertsum_bleu = get_bleu(mlsum_bertsum_sum, mlsum_bertsum_tgt)\n",
    "bertsum_meteor = get_meteor(mlsum_bertsum_sum, mlsum_bertsum_tgt)\n",
    "bertsum_bert_score = get_bert_score(mlsum_bertsum_sum, mlsum_bertsum_tgt)\n",
    "print(\"Done\")"
   ],
   "execution_count": 16,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "hash_code: bert-base-german-dbmdz-cased_L9_idf_version=0.3.9(hug_trans=4.5.1)\n",
      "Done\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "5PBz9lKV-Aus",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1620316985903,
     "user_tz": -120,
     "elapsed": 4011500,
     "user": {
      "displayName": "Zohaib Akhtar Khan",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhDxR5SUI_CQuZ4d1iYZsq0ZqAkxd2KNHJ9ahkuVg=s64",
      "userId": "11760862558786327949"
     }
    },
    "outputId": "64a497ef-eb5f-4620-aa0f-4e90c42026a1"
   },
   "source": [
    "rnd_rouge = get_rouge(mlsum_rnd_sum, mlsum_tgt)\n",
    "rnd_bleu = get_bleu(mlsum_rnd_sum, mlsum_tgt)\n",
    "rnd_meteor = get_meteor(mlsum_rnd_sum, mlsum_tgt)\n",
    "rnd_bert_score = get_bert_score(mlsum_rnd_sum, mlsum_tgt)\n",
    "print(\"Done\")"
   ],
   "execution_count": 17,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "hash_code: bert-base-german-dbmdz-cased_L9_idf_version=0.3.9(hug_trans=4.5.1)\n",
      "Done\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "V_hV5A1Dw-BH",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1620317655993,
     "user_tz": -120,
     "elapsed": 4681578,
     "user": {
      "displayName": "Zohaib Akhtar Khan",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhDxR5SUI_CQuZ4d1iYZsq0ZqAkxd2KNHJ9ahkuVg=s64",
      "userId": "11760862558786327949"
     }
    },
    "outputId": "e7bab56d-eba9-4aa9-aa8c-a0c9a1142ce3"
   },
   "source": [
    "lead_rouge =  get_rouge(mlsum_lead_sum, mlsum_tgt)\n",
    "lead_bleu = get_bleu(mlsum_lead_sum, mlsum_tgt)\n",
    "lead_meteor = get_meteor(mlsum_lead_sum, mlsum_tgt)\n",
    "lead_bert_score = get_bert_score(mlsum_lead_sum, mlsum_tgt)\n",
    "print(\"Done\")"
   ],
   "execution_count": 18,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "hash_code: bert-base-german-dbmdz-cased_L9_idf_version=0.3.9(hug_trans=4.5.1)\n",
      "Done\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "95CnXePcxx7I"
   },
   "source": [
    "tr_rouge = get_rouge(mlsum_textrank_sum, mlsum_tgt)\n",
    "tr_bleu = get_bleu(mlsum_textrank_sum, mlsum_tgt)\n",
    "tr_meteor = get_meteor(mlsum_textrank_sum, mlsum_tgt)\n",
    "tr_bert_score = get_bert_score(mlsum_textrank_sum, mlsum_tgt)\n",
    "print(\"Done\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "PRGad9OqjBey",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1620318168051,
     "user_tz": -120,
     "elapsed": 5193619,
     "user": {
      "displayName": "Zohaib Akhtar Khan",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhDxR5SUI_CQuZ4d1iYZsq0ZqAkxd2KNHJ9ahkuVg=s64",
      "userId": "11760862558786327949"
     }
    },
    "outputId": "b438ab9b-fc46-4fa6-ece3-97e4fb74d033"
   },
   "source": [
    "import pandas as pd\n",
    "\n",
    "mlsum_eval_df = pd.DataFrame([\n",
    "    [\"Random-3\",rnd_rouge['rouge-1'],rnd_rouge['rouge-2'],rnd_rouge['rouge-l'],rnd_bleu,rnd_meteor,rnd_bert_score],\n",
    "    [\"Lead-3\",lead_rouge['rouge-1'],lead_rouge['rouge-2'],lead_rouge['rouge-l'],lead_bleu,lead_meteor,lead_bert_score],\n",
    "    [\"TextRank\",tr_rouge['rouge-1'],tr_rouge['rouge-2'],tr_rouge['rouge-l'],tr_bleu,tr_meteor,tr_bert_score],\n",
    "    [\"Oracle\",oracle_rouge['rouge-1'],oracle_rouge['rouge-2'],oracle_rouge['rouge-l'],oracle_bleu,oracle_meteor,oracle_bert_score],\n",
    "    [\"BertSum\",bertsum_rouge['rouge-1'],bertsum_rouge['rouge-2'],bertsum_rouge['rouge-l'],bertsum_bleu,bertsum_meteor,bertsum_bert_score]\n",
    "], columns=[\"Summary\",\"ROUGE-1\",\"ROUGE-2\",\"ROUGE-L\",\"BLEU\",\"METEOR\",\"BERT-Score\"])\n",
    "\n",
    "print(mlsum_eval_df.head(5))\n",
    "mlsum_eval_df.to_csv(\"results/mlsum/eval.csv\", index=False)"
   ],
   "execution_count": 20,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "    Summary   ROUGE-1   ROUGE-2   ROUGE-L       BLEU    METEOR  BERT-Score\n",
      "0  Random-3  0.142578  0.051765  0.125814   3.357033  0.103051    0.565692\n",
      "1    Lead-3  0.366559  0.276914  0.330138  17.374910  0.238569    0.668897\n",
      "2  TextRank  0.192702  0.077680  0.162778   4.427745  0.090128    0.453015\n",
      "3    Oracle  0.553824  0.427898  0.468219  40.446977  0.312505    0.694175\n",
      "4   BertSum  0.395197  0.271116  0.274531  19.787231  0.274527    0.659321\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Go1Vwt9N87QX",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1620298135043,
     "user_tz": -120,
     "elapsed": 866,
     "user": {
      "displayName": "Zohaib Akhtar Khan",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhDxR5SUI_CQuZ4d1iYZsq0ZqAkxd2KNHJ9ahkuVg=s64",
      "userId": "11760862558786327949"
     }
    },
    "outputId": "fa0a4e99-5a51-4f80-9ae2-7bf4f6365386"
   },
   "source": [
    "import pandas as pd\n",
    "\n",
    "mlsum_eval_df = pd.read_csv(\"results/mlsum/eval.csv\")\n",
    "mlsum_eval_new_df = pd.DataFrame([\n",
    "    [\"Oracle\",oracle_rouge['rouge-1'],oracle_rouge['rouge-2'],oracle_rouge['rouge-l'],oracle_bleu,oracle_meteor,oracle_bert_score],\n",
    "    [\"BertSum\",bertsum_rouge['rouge-1'],bertsum_rouge['rouge-2'],bertsum_rouge['rouge-l'],bertsum_bleu,bertsum_meteor,bertsum_bert_score]\n",
    "], columns=[\"Summary\",\"ROUGE-1\",\"ROUGE-2\",\"ROUGE-L\",\"BLEU\",\"METEOR\",\"BERT-Score\"])\n",
    "mlsum_eval_df = mlsum_eval_df.append(mlsum_eval_new_df, ignore_index=True)\n",
    "\n",
    "print(mlsum_eval_df.head(5))\n",
    "mlsum_eval_df.to_csv(\"results/mlsum/eval.csv\", index=False)"
   ],
   "execution_count": 22,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "    Summary   ROUGE-1   ROUGE-2   ROUGE-L       BLEU    METEOR  BERT-Score\n",
      "0  Random-3  0.146089  0.049990  0.107071   3.645260  0.098402    0.544482\n",
      "1    Lead-3  0.359463  0.263057  0.282831  17.080397  0.228436    0.654696\n",
      "2  TextRank  0.194648  0.074695  0.146609   4.922404  0.087147    0.454724\n",
      "3    Oracle  0.553824  0.427898  0.468219  40.446977  0.312505    0.708408\n",
      "4   BertSum  0.395197  0.271116  0.274531  19.787231  0.274527    0.681540\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sxkixNu5vZsy"
   },
   "source": [
    "# GeWiki"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "cC_OomgXvgif",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1620320245563,
     "user_tz": -120,
     "elapsed": 7271127,
     "user": {
      "displayName": "Zohaib Akhtar Khan",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhDxR5SUI_CQuZ4d1iYZsq0ZqAkxd2KNHJ9ahkuVg=s64",
      "userId": "11760862558786327949"
     }
    },
    "outputId": "f991f35f-e06d-414e-beb7-43a018dcd6bb"
   },
   "source": [
    "# fetch GeWiki data splits from their github repo: https://github.com/domfr/GeWiki\n",
    "\n",
    "# Uncomment below lines, to fetch the GeWiki data, unzipping it, and merging mutiple files into one based on \"src\" or \"tgt\" for train, eval and test splits\n",
    "\n",
    "#!wget -nv -i data/gewiki_urls.txt -O data/gewiki/gewiki.zip\n",
    "#!unzip data/gewiki/gewiki.zip -d data/gewiki/\n",
    "#!awk 'BEGINFILE {print \"[SEP]\"}{print}' data/gewiki/test/*.src > data/gewiki/test_src.txt\n",
    "#!awk 'BEGINFILE {print \"[SEP]\"}{print}' data/gewiki/test/*.tgt > data/gewiki/test_tgt.txt\n",
    "#!awk 'BEGINFILE {print \"[SEP]\"}{print}' data/gewiki/eval/*.src > data/gewiki/validation_src.txt\n",
    "#!awk 'BEGINFILE {print \"[SEP]\"}{print}' data/gewiki/eval/*.tgt > data/gewiki/validation_tgt.txt\n",
    "#!awk 'BEGINFILE {print \"[SEP]\"}{print}' data/gewiki/train/*.src > data/gewiki/train_src.txt\n",
    "#!awk 'BEGINFILE {print \"[SEP]\"}{print}' data/gewiki/train/*.tgt > data/gewiki/train_tgt.txt\n",
    "\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "def merge_src_tgt_to_csv(num_of_files: int, csv_name: str) -> None:\n",
    "    results = defaultdict(list)\n",
    "\n",
    "    with open(f\"data/gewiki/{csv_name}_src.txt\", \"r\") as src:\n",
    "        src = src.read()\n",
    "    with open(f\"data/gewiki/{csv_name}_tgt.txt\", \"r\") as tgt:\n",
    "        tgt = tgt.read()\n",
    "\n",
    "    src_list = src.split(\"[SEP]\")\n",
    "    tgt_list = tgt.split(\"[SEP]\")\n",
    "    for i in tqdm(range(1, num_of_files + 1)):\n",
    "        results[\"text\"].append(src_list[i])\n",
    "        results[\"summary\"].append(tgt_list[i])\n",
    "    df = pd.DataFrame(results)\n",
    "    df.to_csv(f\"data/gewiki/{csv_name}.csv\", False)\n",
    "\n",
    "# Creating Train CSV\n",
    "# merge_src_tgt_to_csv(220000, \"train\")\n",
    "\n",
    "# Creating Eval CSV\n",
    "# merge_src_tgt_to_csv(10000, \"valid\")\n",
    "\n",
    "# Creating Test CSV\n",
    "# merge_src_tgt_to_csv(10000, \"test\")\n",
    "\n",
    "for corpus_type in ['train', 'valid', 'test']:\n",
    "    gewiki_dataset = pd.read_csv(f\"data/gewiki/{corpus_type}.csv\")\n",
    "    data_prep_for_BertSum(gewiki_dataset, 'german', \"json_data/gewiki\", corpus_type)"
   ],
   "execution_count": 21,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "Sentence splitting, tokenizing and converting 'train' split to json...\n",
      "Sentence splitting, tokenizing and converting 'valid' split to json...\n",
      "Sentence splitting, tokenizing and converting 'test' split to json...\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "60gCoXOC2wnU",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1620320471183,
     "user_tz": -120,
     "elapsed": 225532,
     "user": {
      "displayName": "Zohaib Akhtar Khan",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhDxR5SUI_CQuZ4d1iYZsq0ZqAkxd2KNHJ9ahkuVg=s64",
      "userId": "11760862558786327949"
     }
    },
    "outputId": "daadaa4b-33c0-4acf-dbbd-ddd960014c0d"
   },
   "source": [
    "import pandas as pd\n",
    "\n",
    "# generating summaries only for the test set\n",
    "gewiki_dataset = pd.read_csv(\"data/gewiki/test.csv\").iterrows()\n",
    "gewiki_src, gewiki_rnd_sum, gewiki_lead_sum, gewiki_textrank_sum, gewiki_tgt = map(list,zip(*[(\n",
    "                                                      row['text'],\n",
    "                                                      get_random_summary(row['text']),\n",
    "                                                      get_lead_summary(row['text']),\n",
    "                                                      get_textrank_summary(row['text'], 0.06),\n",
    "                                                      row['summary']\n",
    "                                                    ) for index, row in gewiki_dataset]))\n",
    "print(len(gewiki_src))\n",
    "print(len(gewiki_rnd_sum))\n",
    "print(len(gewiki_lead_sum))\n",
    "print(len(gewiki_textrank_sum))\n",
    "print(len(gewiki_tgt))"
   ],
   "execution_count": 22,
   "outputs": [
    {
     "output_type": "stream",
     "text": [
      "10000\n",
      "10000\n",
      "10000\n",
      "10000\n",
      "10000\n"
     ],
     "name": "stdout"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 442
    },
    "id": "sXnQDnniMCCT",
    "executionInfo": {
     "status": "error",
     "timestamp": 1620320472147,
     "user_tz": -120,
     "elapsed": 226476,
     "user": {
      "displayName": "Zohaib Akhtar Khan",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhDxR5SUI_CQuZ4d1iYZsq0ZqAkxd2KNHJ9ahkuVg=s64",
      "userId": "11760862558786327949"
     }
    },
    "outputId": "fcfe6d2f-7a81-4e4f-c472-cdfdcf079e40"
   },
   "source": [
    "import pandas as pd\n",
    "\n",
    "gewiki_oracle_sum = pd.read_csv(\"results/gewiki/oracle_step0_hypo.csv\")['hypothesis'].fillna('').tolist()\n",
    "gewiki_oracle_tgt = pd.read_csv(\"results/gewiki/oracle_step0_ref.csv\")['references'].fillna('').tolist()\n",
    "gewiki_bertsum_sum = pd.read_csv(\"results/gewiki/bertsum_step7000_hypo.csv\")['hypothesis'].fillna('').tolist()\n",
    "gewiki_bertsum_tgt = pd.read_csv(\"results/gewiki/bertsum_step7000_ref.csv\")['references'].fillna('').tolist()"
   ],
   "execution_count": 23,
   "outputs": [
    {
     "output_type": "error",
     "ename": "FileNotFoundError",
     "evalue": "ignored",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-23-b60245119cda>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m()\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mpandas\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0mpd\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      2\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 3\u001B[0;31m \u001B[0mgewiki_oracle_sum\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mpd\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mread_csv\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"results/gewiki/oracle_step0_hypo.csv\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m'hypothesis'\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfillna\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m''\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtolist\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      4\u001B[0m \u001B[0mgewiki_oracle_tgt\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mpd\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mread_csv\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"results/gewiki/oracle_step0_ref.csv\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m'references'\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfillna\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m''\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtolist\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      5\u001B[0m \u001B[0mgewiki_bertsum_sum\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mpd\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mread_csv\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"results/gewiki/bertsum_step7000_hypo.csv\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m'hypothesis'\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfillna\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m''\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtolist\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001B[0m in \u001B[0;36mread_csv\u001B[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001B[0m\n\u001B[1;32m    686\u001B[0m     )\n\u001B[1;32m    687\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 688\u001B[0;31m     \u001B[0;32mreturn\u001B[0m \u001B[0m_read\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfilepath_or_buffer\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mkwds\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    689\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    690\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001B[0m in \u001B[0;36m_read\u001B[0;34m(filepath_or_buffer, kwds)\u001B[0m\n\u001B[1;32m    452\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    453\u001B[0m     \u001B[0;31m# Create the parser.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 454\u001B[0;31m     \u001B[0mparser\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mTextFileReader\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfp_or_buf\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwds\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    455\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    456\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0mchunksize\u001B[0m \u001B[0;32mor\u001B[0m \u001B[0miterator\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001B[0m in \u001B[0;36m__init__\u001B[0;34m(self, f, engine, **kwds)\u001B[0m\n\u001B[1;32m    946\u001B[0m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0moptions\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m\"has_index_names\"\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mkwds\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m\"has_index_names\"\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    947\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 948\u001B[0;31m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_make_engine\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mengine\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    949\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    950\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0mclose\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001B[0m in \u001B[0;36m_make_engine\u001B[0;34m(self, engine)\u001B[0m\n\u001B[1;32m   1178\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m_make_engine\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mengine\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m\"c\"\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1179\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mengine\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0;34m\"c\"\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1180\u001B[0;31m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_engine\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mCParserWrapper\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mf\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0moptions\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1181\u001B[0m         \u001B[0;32melse\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1182\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0mengine\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0;34m\"python\"\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.7/dist-packages/pandas/io/parsers.py\u001B[0m in \u001B[0;36m__init__\u001B[0;34m(self, src, **kwds)\u001B[0m\n\u001B[1;32m   2008\u001B[0m         \u001B[0mkwds\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m\"usecols\"\u001B[0m\u001B[0;34m]\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0musecols\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   2009\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 2010\u001B[0;31m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_reader\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mparsers\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mTextReader\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0msrc\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwds\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   2011\u001B[0m         \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0munnamed_cols\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_reader\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0munnamed_cols\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   2012\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32mpandas/_libs/parsers.pyx\u001B[0m in \u001B[0;36mpandas._libs.parsers.TextReader.__cinit__\u001B[0;34m()\u001B[0m\n",
      "\u001B[0;32mpandas/_libs/parsers.pyx\u001B[0m in \u001B[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001B[0;34m()\u001B[0m\n",
      "\u001B[0;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: 'results/gewiki/oracle_step0_hypo.csv'"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "SQ49VjoSMC8I",
    "executionInfo": {
     "status": "aborted",
     "timestamp": 1620320472139,
     "user_tz": -120,
     "elapsed": 226460,
     "user": {
      "displayName": "Zohaib Akhtar Khan",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhDxR5SUI_CQuZ4d1iYZsq0ZqAkxd2KNHJ9ahkuVg=s64",
      "userId": "11760862558786327949"
     }
    }
   },
   "source": [
    "oracle_rouge = get_rouge(gewiki_oracle_sum, gewiki_oracle_tgt)\n",
    "oracle_bleu = get_bleu(gewiki_oracle_sum, gewiki_oracle_tgt)\n",
    "oracle_meteor = get_meteor(gewiki_oracle_sum, gewiki_oracle_tgt)\n",
    "oracle_bert_score = get_bert_score(gewiki_oracle_sum, gewiki_oracle_tgt)\n",
    "print(\"Done\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "bLzKspQ6MDKW",
    "executionInfo": {
     "status": "aborted",
     "timestamp": 1620320472142,
     "user_tz": -120,
     "elapsed": 226456,
     "user": {
      "displayName": "Zohaib Akhtar Khan",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhDxR5SUI_CQuZ4d1iYZsq0ZqAkxd2KNHJ9ahkuVg=s64",
      "userId": "11760862558786327949"
     }
    }
   },
   "source": [
    "bertsum_rouge = get_rouge(gewiki_bertsum_sum, gewiki_bertsum_tgt)\n",
    "bertsum_bleu = get_bleu(gewiki_bertsum_sum, gewiki_bertsum_tgt)\n",
    "bertsum_meteor = get_meteor(gewiki_bertsum_sum, gewiki_bertsum_tgt)\n",
    "bertsum_bert_score = get_bert_score(gewiki_bertsum_sum, gewiki_bertsum_tgt)\n",
    "print(\"Done\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "t-iCuHlo4NB3",
    "executionInfo": {
     "status": "aborted",
     "timestamp": 1620320472144,
     "user_tz": -120,
     "elapsed": 226446,
     "user": {
      "displayName": "Zohaib Akhtar Khan",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhDxR5SUI_CQuZ4d1iYZsq0ZqAkxd2KNHJ9ahkuVg=s64",
      "userId": "11760862558786327949"
     }
    }
   },
   "source": [
    "rnd_rouge = get_rouge(gewiki_rnd_sum, gewiki_tgt)\n",
    "rnd_bleu = get_bleu(gewiki_rnd_sum, gewiki_tgt)\n",
    "rnd_meteor = get_meteor(gewiki_rnd_sum, gewiki_tgt)\n",
    "rnd_bert_score = get_bert_score(gewiki_rnd_sum, gewiki_tgt)\n",
    "print(\"Done\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "FLPASq0_4Pxt",
    "executionInfo": {
     "status": "aborted",
     "timestamp": 1620320472145,
     "user_tz": -120,
     "elapsed": 226434,
     "user": {
      "displayName": "Zohaib Akhtar Khan",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhDxR5SUI_CQuZ4d1iYZsq0ZqAkxd2KNHJ9ahkuVg=s64",
      "userId": "11760862558786327949"
     }
    }
   },
   "source": [
    "lead_rouge = get_rouge(gewiki_lead_sum, gewiki_tgt)\n",
    "lead_bleu = get_bleu(gewiki_lead_sum, gewiki_tgt)\n",
    "lead_meteor = get_meteor(gewiki_lead_sum, gewiki_tgt)\n",
    "lead_bert_score = get_bert_score(gewiki_lead_sum, gewiki_tgt)\n",
    "print(\"Done\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "EWKvg54S4Qib",
    "executionInfo": {
     "status": "aborted",
     "timestamp": 1620320472145,
     "user_tz": -120,
     "elapsed": 226426,
     "user": {
      "displayName": "Zohaib Akhtar Khan",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhDxR5SUI_CQuZ4d1iYZsq0ZqAkxd2KNHJ9ahkuVg=s64",
      "userId": "11760862558786327949"
     }
    }
   },
   "source": [
    "tr_rouge = get_rouge(gewiki_textrank_sum, gewiki_tgt)\n",
    "tr_bleu = get_bleu(gewiki_textrank_sum, gewiki_tgt)\n",
    "tr_meteor = get_meteor(gewiki_textrank_sum, gewiki_tgt)\n",
    "tr_bert_score = get_bert_score(gewiki_textrank_sum, gewiki_tgt)\n",
    "print(\"Done\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "L1T45sJv-2QP",
    "executionInfo": {
     "status": "aborted",
     "timestamp": 1620320472146,
     "user_tz": -120,
     "elapsed": 226417,
     "user": {
      "displayName": "Zohaib Akhtar Khan",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhDxR5SUI_CQuZ4d1iYZsq0ZqAkxd2KNHJ9ahkuVg=s64",
      "userId": "11760862558786327949"
     }
    }
   },
   "source": [
    "import pandas as pd\n",
    "\n",
    "gewiki_eval_df = pd.DataFrame([\n",
    "    [\"Random-3\",rnd_rouge['rouge-1'],rnd_rouge['rouge-2'],rnd_rouge['rouge-l'],rnd_bleu,rnd_meteor,rnd_bert_score],\n",
    "    [\"Lead-3\",lead_rouge['rouge-1'],lead_rouge['rouge-2'],lead_rouge['rouge-l'],lead_bleu,lead_meteor,lead_bert_score],\n",
    "    [\"TextRank\",tr_rouge['rouge-1'],tr_rouge['rouge-2'],tr_rouge['rouge-l'],tr_bleu,tr_meteor,tr_bert_score],\n",
    "    [\"Oracle\",oracle_rouge['rouge-1'],oracle_rouge['rouge-2'],oracle_rouge['rouge-l'],oracle_bleu,oracle_meteor,oracle_bert_score],\n",
    "    [\"BertSum\",bertsum_rouge['rouge-1'],bertsum_rouge['rouge-2'],bertsum_rouge['rouge-l'],bertsum_bleu,bertsum_meteor,bertsum_bert_score]\n",
    "], columns=[\"Summary\",\"ROUGE-1\",\"ROUGE-2\",\"ROUGE-L\",\"BLEU\",\"METEOR\",\"BERT-Score\"])\n",
    "\n",
    "print(gewiki_eval_df.head(5))\n",
    "gewiki_eval_df.to_csv(\"results/gewiki/eval.csv\", index=False)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "5k7T0Kd-ND4G"
   },
   "source": [
    "import pandas as pd\n",
    "\n",
    "gewiki_eval_df = pd.read_csv(\"results/gewiki/eval.csv\")\n",
    "gewiki_eval_new_df = pd.DataFrame([\n",
    "    [\"Oracle\",oracle_rouge['rouge-1'],oracle_rouge['rouge-2'],oracle_rouge['rouge-l'],oracle_bleu,oracle_meteor,oracle_bert_score],\n",
    "    [\"BertSum\",bertsum_rouge['rouge-1'],bertsum_rouge['rouge-2'],bertsum_rouge['rouge-l'],bertsum_bleu,bertsum_meteor,bertsum_bert_score]\n",
    "], columns=[\"Summary\",\"ROUGE-1\",\"ROUGE-2\",\"ROUGE-L\",\"BLEU\",\"METEOR\",\"BERT-Score\"])\n",
    "gewiki_eval_df = gewiki_eval_df.append(gewiki_eval_new_df, ignore_index=True)\n",
    "\n",
    "print(gewiki_eval_df.head(5))\n",
    "gewiki_eval_df.to_csv(\"results/gewiki/eval.csv\", index=False)"
   ],
   "execution_count": null,
   "outputs": []
  }
 ]
}